{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393faa9e",
   "metadata": {},
   "source": [
    "# How 🤗 Transformers solve tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76167d9",
   "metadata": {},
   "source": [
    "在Transformers, what can they do?中，您了解了自然语言处理（NLP）、语音和音频、计算机视觉任务以及它们的一些重要应用。本页将仔细探讨模型如何解决这些任务，并解释其内部原理。解决给定任务的方法有很多，某些模型可能会采用特定的技术，甚至从新的角度来处理任务，但对于 Transformer 模型来说，其总体思路是相同的。由于其灵活的架构，大多数模型都是编码器、解码器或编码器 - 解码器结构的变体。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a959591",
   "metadata": {},
   "source": [
    "在深入探讨具体的架构变体之前，先理解大多数任务都遵循类似的模式是有帮助的：输入数据通过模型进行处理，然后对输出进行特定任务的解读。不同之处在于数据的准备方式、所使用的模型架构变体以及输出的处理方式。\n",
    "\n",
    "为了解释任务是如何解决的，我们将详细探讨模型内部的运作机制，以输出有用的预测结果。我们将涵盖以下模型及其对应的任务：\n",
    "\n",
    "- BERT: 用于自然语言处理任务（如文本分类、token分类和问答）的 BERT 编码器\n",
    "- GPT2: 用于诸如文本生成等自然语言处理任务的 GPT2，它使用解码器\n",
    "- BERT: 用于诸如摘要和翻译等自然语言处理任务的 BART 编码器 - 解码器\n",
    "\n",
    "\n",
    "在继续之前，了解原始 Transformer 架构的一些基础知识会很有帮助。了解编码器、解码器和注意力机制的工作原理将有助于您理解不同的 Transformer 模型是如何工作的。请务必查看上一节以获取更多信息！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7f813",
   "metadata": {},
   "source": [
    "## Transformer models for language\n",
    "\n",
    "语言模型是现代自然语言处理的核心。它们旨在通过学习文本中单词或标记之间的统计模式和关系来理解和生成人类语言。\n",
    "\n",
    "Transformer 最初是为机器翻译而设计的，从那以后，它已成为解决所有人工智能任务的默认架构。有些任务适合 Transformer 的编码器结构，而有些任务则更适合解码器。还有一些任务则同时利用了 Transformer 的编码器 - 解码器结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a4a6b",
   "metadata": {},
   "source": [
    "### How language models work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cab9b7",
   "metadata": {},
   "source": [
    "语言模型通过训练来预测给定周围词语上下文的某个词出现的概率而发挥作用。这使它们具备了对语言的基础理解能力，能够推广应用于其他任务。\n",
    "\n",
    "训练一个transformer模型主要有两种方法：\n",
    "\n",
    "1. Masked language modeling（MLM）：像 BERT 这样的编码器模型所采用的方法，它会随机遮蔽输入中的某些标记，并训练模型根据上下文预测原始标记。这使得模型能够学习双向上下文（即同时考虑被遮蔽词之前和之后的词）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
