{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d33e73",
   "metadata": {},
   "source": [
    "## A full training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d111a",
   "metadata": {},
   "source": [
    "é¢„å¤„ç†æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f9206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295348023c9f40639eb8f69cecc26bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bca1fcea0645a2b5d79f13596507f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bab3e8c88b467abb6e6321286d8d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b998318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883d920",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3be4db",
   "metadata": {},
   "source": [
    "åœ¨è®­ç»ƒä¹‹å‰æˆ‘ä»¬éœ€è¦å®ä¾‹åŒ–ä¸€äº›å¯¹è±¡. ç¬¬ä¸€ä¸ªå°±æ˜¯ç”¨æ¥éå†batchçš„`dataloaders`ã€‚ä½†åœ¨æ­¤ä¹‹å‰æˆ‘ä»¬éœ€è¦å¯¹`tokenized_datasets`ä½œä¸€äº›å¤„ç†ï¼ˆåœ¨ä¹‹å‰trainerè‡ªåŠ¨å¸®æˆ‘ä»¬åšäº†ï¼‰ï¼Œå…·ä½“ï¼š\n",
    "- å»é™¤æ‰ä¸€äº›modelä¸éœ€è¦çš„åˆ—\n",
    "- å°†labelæ”¹ä¸ºlabels(å› ä¸ºmodelå‚æ•°è¢«å‘½åä¸ºlabels)\n",
    "- è®¾ç½®datasetsçš„æ ¼å¼ï¼Œä½¿å…¶è¿”å›torch.tensorè€Œä¸æ˜¯list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00311d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\",\"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b35b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71301202",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥å®šä¹‰loaderäº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "# æ³¨æ„ï¼Œåœ¨éªŒè¯é›†ä¸­å¹¶æ²¡æœ‰æ‰“ä¹±é¡ºåº shuffle=None\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset=tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f745da4",
   "metadata": {},
   "source": [
    "ä¸ºäº†å¿«é€Ÿæ£€æŸ¥æˆ‘ä»¬åœ¨æ•°æ®å¤„ç†çš„è¿‡ç¨‹ä¸­æ˜¯å¦æœ‰é”™è¯¯ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥ä¸€ä¸ªbatchåƒè¿™æ ·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9f5f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([8]),\n",
       " 'input_ids': torch.Size([8, 69]),\n",
       " 'token_type_ids': torch.Size([8, 69]),\n",
       " 'attention_mask': torch.Size([8, 69])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2226d",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å·²ç»å®Œæˆäº†æ•°æ®é¢„å¤„ç†ï¼Œæ¥ä¸‹æ¥å¼€å§‹å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322cd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a46e0",
   "metadata": {},
   "source": [
    "ä¸ºç¡®ä¿ä¸€åˆ‡æ­£å¸¸è¿è¡Œï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¹‹å‰çš„bachæ”¾å…¥modelä¸­è¯•ç€è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f6b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([1, 0, 0, 1, 0, 1, 1, 0]), 'input_ids': tensor([[  101,  1996,  2924,  2036,  2056,  2049,  3749,  2001,  3395,  2000,\n",
      "          1996,  3820,  1997,  2852,  8528,  1005,  1055,  3026,  5085,  1010,\n",
      "          3026,  5416, 13304,  1998,  2002,  2094,  4726,  5085,  2011,  2382,\n",
      "          2244,  2494,  1012,   102,  1996,  3749,  2003,  2036,  3395,  2000,\n",
      "         17765,  6608,  2019,  3820,  2007,  2852,  8528,  1005,  1055,  3026,\n",
      "          5085,  1010,  3026,  5416, 13304,  1998,  2002,  2094,  4726,  5085,\n",
      "          2011, 17419,  1012,  2382,  1010,  2009,  2056,  1012,   102],\n",
      "        [  101,  2016,  2038,  1037,  6898,  1010,  2205,  1010,  4584,  2056,\n",
      "          1024, 17001,  1012, 19469,  9530,  7913,  8180,  1010,  2040,  2938,\n",
      "          2007,  2014,  2155,  9857,  1012,   102,  2016,  2036, 15583,  2014,\n",
      "          6898,  1010, 17001,  1012, 19469,  9530,  7913,  8180,  1010,  2040,\n",
      "          2001,  3564,  2279,  2000,  1996,  2754,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2197,  2733,  1010,  2010,  9559,  2356,  6654,  2000,  3946,\n",
      "         18856, 21382,  9407,  2104,  3785,  2008,  2052,  2031,  2599,  2000,\n",
      "          1037,  2047, 23280,  4994,  1012,   102,  2197,  2733,  1010,  2010,\n",
      "          9559,  2356, 18079,  1012,  2928,  1054,  1012,  6654,  2000,  3946,\n",
      "         18856, 21382,  9407,  1010,  2021,  1996,  3099,  6430,  2000, 18793,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4001,  6019,  1997,  1996, 27615,  3021,  2001,  2471,  3056,\n",
      "          1010,  4298,  2004,  2220,  2004,  2651,  1012,   102,  4001,  6019,\n",
      "          1997,  1996, 27615,  3021,  2003,  2471,  3056,  6928,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13208,  1004,  9809,  2018,  2056,  2008,  4293,  2566,  9358,\n",
      "          1997,  1996,  3194,  3941,  2052,  2022, 21100,  8162, 11788,  2000,\n",
      "          2885,  1010,  2007,  2345,  3320,  1999,  2762,  1012,   102, 13208,\n",
      "          1004,  9809,  2018,  2056,  2008,  2065,  2009,  2180,  1996,  3206,\n",
      "          4293,  2566,  9358,  1997,  1996,  3194,  3941,  2052,  2022, 21100,\n",
      "          8162, 11788,  2000,  2647, 20141,  1010,  2007,  2345,  3320,  1999,\n",
      "          2762,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2309,  9598,  3333,  2000, 15407,  1012,  6365, 18371,\n",
      "          4102,  2007,  2049,  2397,  1057,  1012,  1055,  1012,  2504,  1997,\n",
      "         14989,  1012,  4185,  1012,   102,  2114,  1996,  2887,  9598,  1010,\n",
      "          1996,  9944,  2001,  2012, 15407,  1012,  5757, 18371,  4102,  2007,\n",
      "          1996,  2397,  2047,  2259,  2504,  1997, 15407,  1012,  6021,  1013,\n",
      "          2403,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019,  3063,  2038,  1999, 27942, 15070,  2047, 19095,  2015,\n",
      "          2011,  4169,  1037,  3696,  3752,  1000, 14046,  2659,  3909,  9738,\n",
      "          1000,  2006,  1037,  2311,  2379,  2598,  5717,  1012,   102,  2019,\n",
      "          3063,  4993,  1037,  3696,  3752,  1036,  1036, 14046,  2659,  3909,\n",
      "          9738,  1005,  1005,  2006,  1037,  2311,  2379,  2598,  5717,  1010,\n",
      "          4963,  2075, 10638,  1998, 18385, 10821,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2047,  3317,  2221,  2450,  2038,  2468,  1996,  2034,\n",
      "          8452,  5776,  2000,  3206,  1996,  2225, 15179,  7865,  2023,  2095,\n",
      "          1010,  1996,  2110,  1005,  1055,  2533,  1997,  2740,  2988,  1012,\n",
      "           102,  1037,  5786,  1011,  2095,  1011,  2214,  2225, 17690,  2158,\n",
      "          2038, 11016,  1996,  2225, 15179,  7865,  1010,  1996,  2034,  2529,\n",
      "          2553,  1999, 12291,  2221,  2023,  2095,  1010,  2429,  2000,  1996,\n",
      "          2221,  2740,  2533,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "tensor(0.6906, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73ece5",
   "metadata": {},
   "source": [
    "å½“æ•°æ®å«æœ‰labelsæ—¶ï¼Œæ‰€æœ‰çš„transformersæ¨¡å‹å°†è¿”å›loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586185b",
   "metadata": {},
   "source": [
    "ç°åœ¨è¿˜æœ‰æœ€åä¸¤ä»¶äº‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹training loop!\n",
    "- å®šä¹‰optimizerå’Œlearning rate scheduler\n",
    "- use GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e0b7e",
   "metadata": {},
   "source": [
    "å®šä¹‰optimizerå’Œlearning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e4084cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71f138",
   "metadata": {},
   "source": [
    "æœ€åï¼Œé»˜è®¤ä½¿ç”¨çš„å­¦ä¹ ç‡è°ƒåº¦å™¨åªæ˜¯ä»æœ€å¤§å€¼ï¼ˆ5e-5ï¼‰çº¿æ€§è¡°å‡è‡³ 0ã€‚è¦æ­£ç¡®å®šä¹‰å®ƒï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å°†è¦é‡‡å–çš„è®­ç»ƒæ­¥æ•°ï¼Œå³æˆ‘ä»¬æƒ³è¦è¿è¡Œçš„è½®æ•°ä¹˜ä»¥è®­ç»ƒæ‰¹æ¬¡çš„æ•°é‡ï¼ˆä¹Ÿå°±æ˜¯æˆ‘ä»¬è®­ç»ƒæ•°æ®åŠ è½½å™¨çš„é•¿åº¦ï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒTrainer ä½¿ç”¨ä¸‰è½®ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå°†éµå¾ªè¿™ä¸€è®¾ç½®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca62081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ddf9c",
   "metadata": {},
   "source": [
    "use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f294714",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬éœ€è¦å°†ä¸¤ä¸ªä¸œè¥¿æ”¾å…¥GPUä¸­\n",
    "- model\n",
    "- batches\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "485962ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# pythonçš„ä¸‰å…ƒè¡¨è¾¾å¼ val1 if æ¡ä»¶1 else val2\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73f177",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¼€å§‹è®­ç»ƒï¼ä¸ºäº†å¤§è‡´äº†è§£è®­ç»ƒä½•æ—¶ç»“æŸï¼Œæˆ‘ä»¬ä½¿ç”¨ tqdm åº“åœ¨è®­ç»ƒæ­¥æ•°ä¸Šæ·»åŠ äº†ä¸€ä¸ªè¿›åº¦æ¡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d5b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c85aeb7fa54b1eb6b5149a80109783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        # è¿™æ ·å†™çš„ç›®çš„æ˜¯æŠŠbatchä¸­çš„å…ƒç´ æ”¾åˆ°GPU\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        # æ³¨æ„zero_grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # æ›´æ–°è¿›åº¦æ¡: å³æ¯ä¸ªbatchè®­ç»ƒå®Œåæ›´æ–°ä¸€æ¬¡è¿›åº¦æ¡\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b4f56",
   "metadata": {},
   "source": [
    "å¯ä»¥çœ‹åˆ°ï¼Œè®­ç»ƒå¾ªç¯çš„æ ¸å¿ƒéƒ¨åˆ†ä¸ä»‹ç»ä¸­çš„éå¸¸ç›¸ä¼¼ã€‚æˆ‘ä»¬æ²¡æœ‰è¦æ±‚ä»»ä½•æŠ¥å‘Šï¼Œæ‰€ä»¥è¿™ä¸ªè®­ç»ƒå¾ªç¯ä¸ä¼šå‘Šè¯‰æˆ‘ä»¬æ¨¡å‹çš„è¡¨ç°å¦‚ä½•ã€‚ä¸ºæ­¤æˆ‘ä»¬éœ€è¦æ·»åŠ ä¸€ä¸ªè¯„ä¼°å¾ªç¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde919b4",
   "metadata": {},
   "source": [
    "### The evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a9b6e",
   "metadata": {},
   "source": [
    "å’Œä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ğŸ¤— Evaluate åº“æä¾›çš„ä¸€ä¸ªæŒ‡æ ‡ã€‚æˆ‘ä»¬å·²ç»è§è¿‡ metric.compute() æ–¹æ³•ï¼Œä½†æŒ‡æ ‡å®é™…ä¸Šå¯ä»¥é€šè¿‡åœ¨é¢„æµ‹å¾ªç¯ä¸­ä½¿ç”¨ add_batch() æ–¹æ³•ä¸ºæˆ‘ä»¬ç´¯ç§¯æ‰¹æ¬¡ã€‚ä¸€æ—¦ç´¯ç§¯äº†æ‰€æœ‰æ‰¹æ¬¡ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡ metric.compute() è·å–æœ€ç»ˆç»“æœã€‚ä»¥ä¸‹æ˜¯åœ¨è¯„ä¼°å¾ªç¯ä¸­å®ç°è¿™ä¸€åˆ‡çš„æ–¹æ³•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4787a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8455882352941176, 'f1': 0.8904347826086957}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    # çœç•¥åå‘ä¼ æ’­\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    # ç´¯ç§¯æ‰¹æ¬¡\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "# è®¡ç®—metric\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76252e",
   "metadata": {},
   "source": [
    "### Supercharge your training loop with ğŸ¤— Accelerate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
