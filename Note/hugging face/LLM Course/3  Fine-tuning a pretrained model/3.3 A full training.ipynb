{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d33e73",
   "metadata": {},
   "source": [
    "## A full training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d111a",
   "metadata": {},
   "source": [
    "预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f9206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295348023c9f40639eb8f69cecc26bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bca1fcea0645a2b5d79f13596507f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bab3e8c88b467abb6e6321286d8d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b998318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e883d920",
   "metadata": {},
   "source": [
    "### Prepare for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3be4db",
   "metadata": {},
   "source": [
    "在训练之前我们需要实例化一些对象. 第一个就是用来遍历batch的`dataloaders`。但在此之前我们需要对`tokenized_datasets`作一些处理（在之前trainer自动帮我们做了），具体：\n",
    "- 去除掉一些model不需要的列\n",
    "- 将label改为labels(因为model参数被命名为labels)\n",
    "- 设置datasets的格式，使其返回torch.tensor而不是list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00311d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\",\"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b35b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71301202",
   "metadata": {},
   "source": [
    "接下来我们就可以定义loader了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "# 注意，在验证集中并没有打乱顺序 shuffle=None\n",
    "eval_dataloader = DataLoader(\n",
    "    dataset=tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f745da4",
   "metadata": {},
   "source": [
    "为了快速检查我们在数据处理的过程中是否有错误，我们可以检查一个batch像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9f5f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([8]),\n",
       " 'input_ids': torch.Size([8, 69]),\n",
       " 'token_type_ids': torch.Size([8, 69]),\n",
       " 'attention_mask': torch.Size([8, 69])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2226d",
   "metadata": {},
   "source": [
    "现在我们已经完成了数据预处理，接下来开始定义我们的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322cd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a46e0",
   "metadata": {},
   "source": [
    "为确保一切正常运行，我们可以将之前的bach放入model中试着运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f6b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([1, 0, 0, 1, 0, 1, 1, 0]), 'input_ids': tensor([[  101,  1996,  2924,  2036,  2056,  2049,  3749,  2001,  3395,  2000,\n",
      "          1996,  3820,  1997,  2852,  8528,  1005,  1055,  3026,  5085,  1010,\n",
      "          3026,  5416, 13304,  1998,  2002,  2094,  4726,  5085,  2011,  2382,\n",
      "          2244,  2494,  1012,   102,  1996,  3749,  2003,  2036,  3395,  2000,\n",
      "         17765,  6608,  2019,  3820,  2007,  2852,  8528,  1005,  1055,  3026,\n",
      "          5085,  1010,  3026,  5416, 13304,  1998,  2002,  2094,  4726,  5085,\n",
      "          2011, 17419,  1012,  2382,  1010,  2009,  2056,  1012,   102],\n",
      "        [  101,  2016,  2038,  1037,  6898,  1010,  2205,  1010,  4584,  2056,\n",
      "          1024, 17001,  1012, 19469,  9530,  7913,  8180,  1010,  2040,  2938,\n",
      "          2007,  2014,  2155,  9857,  1012,   102,  2016,  2036, 15583,  2014,\n",
      "          6898,  1010, 17001,  1012, 19469,  9530,  7913,  8180,  1010,  2040,\n",
      "          2001,  3564,  2279,  2000,  1996,  2754,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2197,  2733,  1010,  2010,  9559,  2356,  6654,  2000,  3946,\n",
      "         18856, 21382,  9407,  2104,  3785,  2008,  2052,  2031,  2599,  2000,\n",
      "          1037,  2047, 23280,  4994,  1012,   102,  2197,  2733,  1010,  2010,\n",
      "          9559,  2356, 18079,  1012,  2928,  1054,  1012,  6654,  2000,  3946,\n",
      "         18856, 21382,  9407,  1010,  2021,  1996,  3099,  6430,  2000, 18793,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  4001,  6019,  1997,  1996, 27615,  3021,  2001,  2471,  3056,\n",
      "          1010,  4298,  2004,  2220,  2004,  2651,  1012,   102,  4001,  6019,\n",
      "          1997,  1996, 27615,  3021,  2003,  2471,  3056,  6928,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 13208,  1004,  9809,  2018,  2056,  2008,  4293,  2566,  9358,\n",
      "          1997,  1996,  3194,  3941,  2052,  2022, 21100,  8162, 11788,  2000,\n",
      "          2885,  1010,  2007,  2345,  3320,  1999,  2762,  1012,   102, 13208,\n",
      "          1004,  9809,  2018,  2056,  2008,  2065,  2009,  2180,  1996,  3206,\n",
      "          4293,  2566,  9358,  1997,  1996,  3194,  3941,  2052,  2022, 21100,\n",
      "          8162, 11788,  2000,  2647, 20141,  1010,  2007,  2345,  3320,  1999,\n",
      "          2762,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2309,  9598,  3333,  2000, 15407,  1012,  6365, 18371,\n",
      "          4102,  2007,  2049,  2397,  1057,  1012,  1055,  1012,  2504,  1997,\n",
      "         14989,  1012,  4185,  1012,   102,  2114,  1996,  2887,  9598,  1010,\n",
      "          1996,  9944,  2001,  2012, 15407,  1012,  5757, 18371,  4102,  2007,\n",
      "          1996,  2397,  2047,  2259,  2504,  1997, 15407,  1012,  6021,  1013,\n",
      "          2403,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2019,  3063,  2038,  1999, 27942, 15070,  2047, 19095,  2015,\n",
      "          2011,  4169,  1037,  3696,  3752,  1000, 14046,  2659,  3909,  9738,\n",
      "          1000,  2006,  1037,  2311,  2379,  2598,  5717,  1012,   102,  2019,\n",
      "          3063,  4993,  1037,  3696,  3752,  1036,  1036, 14046,  2659,  3909,\n",
      "          9738,  1005,  1005,  2006,  1037,  2311,  2379,  2598,  5717,  1010,\n",
      "          4963,  2075, 10638,  1998, 18385, 10821,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1037,  2047,  3317,  2221,  2450,  2038,  2468,  1996,  2034,\n",
      "          8452,  5776,  2000,  3206,  1996,  2225, 15179,  7865,  2023,  2095,\n",
      "          1010,  1996,  2110,  1005,  1055,  2533,  1997,  2740,  2988,  1012,\n",
      "           102,  1037,  5786,  1011,  2095,  1011,  2214,  2225, 17690,  2158,\n",
      "          2038, 11016,  1996,  2225, 15179,  7865,  1010,  1996,  2034,  2529,\n",
      "          2553,  1999, 12291,  2221,  2023,  2095,  1010,  2429,  2000,  1996,\n",
      "          2221,  2740,  2533,  1012,   102,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}\n",
      "tensor(0.6906, grad_fn=<NllLossBackward0>) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**batch)\n",
    "print(batch)\n",
    "print(outputs.loss, outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73ece5",
   "metadata": {},
   "source": [
    "当数据含有labels时，所有的transformers模型将返回loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586185b",
   "metadata": {},
   "source": [
    "现在还有最后两件事，我们就可以开始training loop!\n",
    "- 定义optimizer和learning rate scheduler\n",
    "- use GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e0b7e",
   "metadata": {},
   "source": [
    "定义optimizer和learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e4084cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71f138",
   "metadata": {},
   "source": [
    "最后，默认使用的学习率调度器只是从最大值（5e-5）线性衰减至 0。要正确定义它，我们需要知道将要采取的训练步数，即我们想要运行的轮数乘以训练批次的数量（也就是我们训练数据加载器的长度）。默认情况下，Trainer 使用三轮，所以我们也将遵循这一设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca62081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ddf9c",
   "metadata": {},
   "source": [
    "use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f294714",
   "metadata": {},
   "source": [
    "我们需要将两个东西放入GPU中\n",
    "- model\n",
    "- batches\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "485962ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# python的三元表达式 val1 if 条件1 else val2\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73f177",
   "metadata": {},
   "source": [
    "现在我们准备开始训练！为了大致了解训练何时结束，我们使用 tqdm 库在训练步数上添加了一个进度条："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d5b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c85aeb7fa54b1eb6b5149a80109783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        # 这样写的目的是把batch中的元素放到GPU\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        # 注意zero_grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 更新进度条: 即每个batch训练完后更新一次进度条\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b4f56",
   "metadata": {},
   "source": [
    "可以看到，训练循环的核心部分与介绍中的非常相似。我们没有要求任何报告，所以这个训练循环不会告诉我们模型的表现如何。为此我们需要添加一个评估循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde919b4",
   "metadata": {},
   "source": [
    "### The evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a9b6e",
   "metadata": {},
   "source": [
    "和之前一样，我们将使用 🤗 Evaluate 库提供的一个指标。我们已经见过 metric.compute() 方法，但指标实际上可以通过在预测循环中使用 add_batch() 方法为我们累积批次。一旦累积了所有批次，我们就可以通过 metric.compute() 获取最终结果。以下是在评估循环中实现这一切的方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4787a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8455882352941176, 'f1': 0.8904347826086957}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    # 省略反向传播\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    # 累积批次\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "# 计算metric\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76252e",
   "metadata": {},
   "source": [
    "### Supercharge your training loop with 🤗 Accelerate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
