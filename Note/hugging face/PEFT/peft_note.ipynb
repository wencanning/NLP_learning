{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicktour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFT Parameter-Efficient Fine-Tuningâ€‹â€‹ï¼‰ä¸ºå¤§å‹é¢„è®­ç»ƒæ¨¡å‹æä¾›äº†å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ã€‚ä¼ ç»Ÿåšæ³•æ˜¯é’ˆå¯¹æ¯ä¸ªä¸‹æ¸¸ä»»åŠ¡å¯¹æ¨¡å‹çš„æ‰€æœ‰å‚æ•°è¿›è¡Œå¾®è°ƒï¼Œä½†ç”±äºå¦‚ä»Šæ¨¡å‹çš„å‚æ•°æ•°é‡åºå¤§ï¼Œè¿™ç§æ–¹æ³•çš„æˆæœ¬è¶Šæ¥è¶Šé«˜ï¼Œä¹Ÿè¶Šæ¥è¶Šä¸åˆ‡å®é™…ã€‚ç›¸åï¼Œè®­ç»ƒè¾ƒå°‘çš„æç¤ºå‚æ•°æˆ–ä½¿ç”¨è¯¸å¦‚ä½ç§©é€‚åº”ï¼ˆLoRA low-rank adaptationï¼‰ä¹‹ç±»çš„é‡æ–°å‚æ•°åŒ–æ–¹æ³•æ¥å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ä¼šæ›´é«˜æ•ˆã€‚\n",
    "\n",
    "æœ¬å¿«é€Ÿå…¥é—¨å°†å‘æ‚¨å±•ç¤º PEFT çš„ä¸»è¦åŠŸèƒ½ï¼Œä»¥åŠå¦‚ä½•åœ¨æ™®é€šæ¶ˆè´¹è€…è®¾å¤‡ä¸Šè®­ç»ƒæˆ–è¿è¡Œé€šå¸¸æ— æ³•è§¦åŠçš„å¤§å‹æ¨¡å‹çš„æ¨ç†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¯ç§å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•éƒ½ç”±ä¸€ä¸ª PeftConfig ç±»å®šä¹‰ï¼Œè¯¥ç±»å­˜å‚¨æ„å»ºPeftModelæ‰€éœ€çš„æ‰€æœ‰é‡è¦å‚æ•°ã€‚ä¾‹å¦‚ï¼Œè‹¥è¦ä½¿ç”¨ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰è¿›è¡Œè®­ç»ƒï¼Œè¯·åŠ è½½å¹¶åˆ›å»ºä¸€ä¸ª LoraConfig ç±»ï¼Œå¹¶æŒ‡å®šä»¥ä¸‹å‚æ•°ï¼š\n",
    "- task_type: ç›®æ ‡ä»»åŠ¡\n",
    "- inference_modeï¼šæ˜¯å¦ä½¿ç”¨æ¨¡å‹æ¥è¿›è¡Œé¢„æµ‹\n",
    "- r: ä½ç§©çŸ©é˜µçš„ç»´åº¦\n",
    "- lora_alphaï¼šä½ç§©çŸ©é˜µçš„ç¼©æ”¾å› å­\n",
    "- lora_dropoutï¼šLoRA å±‚çš„ä¸¢å¼ƒæ¦‚ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T08:01:01.567645Z",
     "iopub.status.busy": "2025-05-13T08:01:01.567244Z",
     "iopub.status.idle": "2025-05-13T08:01:01.573187Z",
     "shell.execute_reply": "2025-05-13T08:01:01.572208Z",
     "shell.execute_reply.started": "2025-05-13T08:01:01.567616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€æ—¦è®¾ç½®å¥½ LoraConfigï¼Œå°±å¯ä»¥ä½¿ç”¨ get_peft_model() å‡½æ•°åˆ›å»ºä¸€ä¸ª PeftModelã€‚è¯¥å‡½æ•°éœ€è¦ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼ˆå¯ä»¥ä» Transformers åº“ä¸­åŠ è½½ï¼‰ä»¥åŠåŒ…å«ç”¨äºä½¿ç”¨ LoRA è®­ç»ƒæ¨¡å‹çš„å‚æ•°çš„ LoraConfigã€‚\n",
    "\n",
    "åŠ è½½æ‚¨æƒ³è¦å¾®è°ƒçš„åŸºç¡€æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T08:01:01.575266Z",
     "iopub.status.busy": "2025-05-13T08:01:01.575015Z",
     "iopub.status.idle": "2025-05-13T08:01:02.350185Z",
     "shell.execute_reply": "2025-05-13T08:01:02.349455Z",
     "shell.execute_reply.started": "2025-05-13T08:01:01.575249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "checkpoint = \"bigscience/mt0-large\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `get_peft_model()` å‡½æ•°`model`å’Œ `peft_config` åŒ…è£…èµ·æ¥ä»¥åˆ›å»ºä¸€ä¸ª `PeftModel`ã€‚è¦äº†è§£æ¨¡å‹ä¸­å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ï¼Œè¯·ä½¿ç”¨ `print_trainable_parameters` æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T08:01:02.351402Z",
     "iopub.status.busy": "2025-05-13T08:01:02.351107Z",
     "iopub.status.idle": "2025-05-13T08:01:02.600629Z",
     "shell.execute_reply": "2025-05-13T08:01:02.599707Z",
     "shell.execute_reply.started": "2025-05-13T08:01:02.351376Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,359,296 || all params: 1,231,940,608 || trainable%: 0.1915\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ bigscience/mt0-large çš„ 12 äº¿å‚æ•°ä¸­ï¼Œæ‚¨åªéœ€è®­ç»ƒå…¶ä¸­çš„ 0.19%ï¼\n",
    "\n",
    "å°±æ˜¯è¿™æ · ğŸ‰ï¼ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ Transformers Trainerã€Accelerate æˆ–ä»»ä½•è‡ªå®šä¹‰çš„ PyTorch è®­ç»ƒå¾ªç¯æ¥è®­ç»ƒæ¨¡å‹ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œè‹¥è¦ä½¿ç”¨ Trainer ç±»è¿›è¡Œè®­ç»ƒï¼Œè¯·è®¾ç½®ä¸€ä¸ªå¸¦æœ‰æŸäº›è®­ç»ƒè¶…å‚æ•°çš„ TrainingArguments ç±»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"your-name/bigscience/mt0-large-lora\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEFT configuration and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºä»»ä½•å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ï¼Œæ‚¨éƒ½éœ€è¦åˆ›å»ºä¸€ä¸ªconfigï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰æŒ‡å®šåº”å¦‚ä½•åº”ç”¨è¯¥ PEFT æ–¹æ³•çš„å‚æ•°ã€‚é…ç½®è®¾ç½®å®Œæˆåï¼Œå°†å…¶ä¸base modelä¸€èµ·ä¼ é€’ç»™ get_peft_model() å‡½æ•°ï¼Œä»¥åˆ›å»ºå¯è®­ç»ƒçš„ PeftModelã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prompt tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æç¤ºè°ƒä¼˜å°†æ‰€æœ‰ä»»åŠ¡éƒ½è§†ä¸ºç”Ÿæˆä»»åŠ¡ï¼Œå¹¶åœ¨è¾“å…¥ä¸­æ·»åŠ ç‰¹å®šäºä»»åŠ¡çš„æç¤ºï¼Œè¯¥æç¤ºä¼šç‹¬ç«‹æ›´æ–°ã€‚`prompt_tuning_init_text` å‚æ•°æŒ‡å®šäº†å¦‚ä½•å¾®è°ƒæ¨¡å‹ï¼ˆåœ¨æœ¬ä¾‹ä¸­ï¼Œæ˜¯åˆ¤æ–­æ¨æ–‡æ˜¯å¦ä¸ºæŠ•è¯‰ï¼‰ã€‚ä¸ºäº†è·å¾—æœ€ä½³æ•ˆæœï¼Œ`prompt_tuning_init_text` åº”è¯¥å…·æœ‰ä¸åº”é¢„æµ‹çš„`token`æ•°é‡ç›¸åŒçš„`token`æ•°ã€‚ä¸ºæ­¤ï¼Œæ‚¨å¯ä»¥å°† `num_virtual_tokens` è®¾ç½®ä¸º `prompt_tuning_init_text` çš„æ ‡è®°æ•°ã€‚\n",
    "\n",
    "\n",
    "åˆ›å»ºä¸€ä¸ª`PromptTuningConfig`ï¼Œå…¶ä¸­åŒ…å«ä»»åŠ¡ç±»å‹ã€ç”¨äºè®­ç»ƒæ¨¡å‹çš„åˆå§‹æç¤ºè°ƒä¼˜æ–‡æœ¬ã€è¦æ·»åŠ å’Œå­¦ä¹ çš„è™šæ‹Ÿ`token`æ•°é‡ï¼Œä»¥åŠä¸€ä¸ª`tokenizer`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PromptTuningConfig, PromptTuningInit, get_peft_model\n",
    "\n",
    "prompt_tuning_init_text = \"Classify if the tweet is a complaint or no complaint.\\n\"\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=len(tokenizer(prompt_tuning_init_text)[\"input_ids\"]),\n",
    "    prompt_tuning_init_text=prompt_tuning_init_text,\n",
    "    tokenizer_name_or_path=\"bigscience/bloomz-560m\",\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prefix tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‰ç¼€è°ƒä¼˜åœ¨æ¨¡å‹çš„æ‰€æœ‰å±‚ä¸­æ·»åŠ ç‰¹å®šä»»åŠ¡çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°ç”±ä¸€ä¸ªå•ç‹¬çš„å‰é¦ˆç½‘ç»œè¿›è¡Œä¼˜åŒ–ã€‚ä½¿ç”¨ä»»åŠ¡ç±»å‹å’Œè¦æ·»åŠ åŠå­¦ä¹ çš„è™šæ‹Ÿtokenæ•°é‡åˆ›å»ºä¸€ä¸ª PrefixTuningConfig é…ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PrefixTuningConfig, get_peft_model\n",
    "\n",
    "peft_config = PrefixTuningConfig(task_type=\"CAUSAL_LM\", num_virtual_tokens=20)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\"trainable params: 983,040 || all params: 560,197,632 || trainable%: 0.1754809274167014\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**p-tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P è°ƒä¼˜æ·»åŠ äº†ä¸€ä¸ªå¯è®­ç»ƒçš„åµŒå…¥å¼ é‡ï¼Œæç¤ºtokenå¯ä»¥åœ¨è¾“å…¥åºåˆ—ä¸­çš„ä»»ä½•ä½ç½®æ·»åŠ ã€‚ä½¿ç”¨ä»»åŠ¡ç±»å‹ã€è¦æ·»åŠ å’Œå­¦ä¹ çš„è™šæ‹Ÿtokenæ•°é‡ä»¥åŠç”¨äºå­¦ä¹ æç¤ºå‚æ•°çš„ç¼–ç å™¨éšè—å¤§å°åˆ›å»ºä¸€ä¸ª PromptEncoderConfigã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PromptEncoderConfig, get_peft_model\n",
    "\n",
    "peft_config = PromptEncoderConfig(\n",
    "    task_type=\"CAUSAL_LM\", \n",
    "    num_virtual_tokens=20, \n",
    "    encoder_hidden_size=128\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
