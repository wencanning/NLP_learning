## 摘要

近年来，对比学习应用于自监督表示学习领域，出现了复兴之势，在深度图像模型的无监督训练中取得了最先进的性能。现代批量对比方法涵盖了或显著优于传统的对比损失，如三元组损失、最大边缘损失和 N 对损失。在本研究中，我们将自监督批量对比方法扩展到全监督设置，从而能够有效利用标签信息。属于同一类别的点簇在嵌入空间中被拉近，同时不同类别样本的簇被推开。我们分析了监督对比（SupCon）损失的两个可能版本，确定了性能最佳的损失公式。在 ResNet-200 上，我们在 ImageNet 数据集上实现了 81.4% 的 top-1 准确率，比该架构的最佳报告数字高出 0.8%。我们在其他数据集和两个 ResNet 变体上展示了相对于交叉熵的持续性的超越。该损失函数显示出对自然干扰的鲁棒性优势，并且对于诸如优化器和数据增强之类的超参数设置更加稳定。我们的损失函数易于实现，并且参考的 TensorFlow 代码已发布在 https://t.ly/supcon 1 。

## 1 Introduction

图 1：我们的 SupCon 损失函数在标准数据增强的情况下始终优于交叉熵。我们展示了在 ResNet-50、ResNet-101 和 ResNet-200 上 ImageNet 数据集的 top-1 准确率，并与 AutoAugment [5]、RandAugment [6] 和 CutMix [60] 进行了比较。

图 2：监督对比损失与自监督对比损失：自监督对比损失（左，公式 1）将每个锚点只与一个正样本进行对比（即同一图像的增强版本）与批次中其余部分的所有负样本进行对比。然而，本文所考虑的监督对比损失（右，公式 2）将来自同一类别的所有样本作为正样本，与批次中其余部分的负样本进行对比。正如黑白小狗的照片所示，考虑类别标签信息会导致嵌入空间中同一类别的元素比自监督情况更紧密地对齐。

交叉熵损失是深度分类模型监督学习中最常用的损失函数。许多研究工作探讨了这种损失函数的不足之处，例如对噪声标签缺乏鲁棒性[64, 46]以及可能导致边界不佳[10, 31]，从而导致泛化性能降低。然而，在实践中，大多数提出的替代方案对于大规模数据集（如 ImageNet [7]）效果并不更好，这一点从交叉熵仍被用于取得最先进的结果[5, 6, 56, 25]中可见一斑。

近年来，对比学习领域的研究再度兴起，这使得自监督表示学习取得了重大进展[55, 18, 38, 48, 22, 3, 15]。这些研究的共同思路是：在嵌入空间中将锚点和一个“正样本”拉近，同时将锚点与多个“负样本”推远。由于没有标签可用，正样本对通常由样本的数据增强形式组成，而负样本对则由锚点和从小批量中随机选取的样本构成。这在图 2（左）中有图示。在[38, 48]中，对比损失与数据不同视图之间互信息的最大化建立了联系。


在这项工作中，我们提出了一种用于监督学习的损失函数，该函数基于对比自监督文献，同时利用了标签信息。来自同一类别的归一化嵌入比来自不同类别的嵌入更紧密地聚集在一起。我们在这项工作中的技术创新在于，除了考虑许多负样本之外，还考虑了每个锚点的多个正样本（与仅使用单个正样本的自监督对比学习不同）。这些正样本是从与锚点属于同一类别的样本中抽取的，而不是像自监督学习那样对锚点进行数据增强。虽然这是对自监督设置的一个简单扩展，但如何正确设置损失函数并不明显，我们分析了两种替代方案。图 2（右）和图 1（补充材料）提供了对我们所提出损失函数的直观解释。我们的损失函数可以看作是三元组损失[53]和 N 对损失[45]的泛化；前者每个锚点仅使用一个正样本和一个负样本，而后者每个锚点使用一个正样本和多个负样本。对于每个锚点使用大量正样本和大量负样本，使我们无需进行难以恰当调整的硬负样本挖掘，就能达到最先进的性能。据我们所知，这是首个在大规模分类问题上始终优于交叉熵损失的对比损失。此外，它提供了一种统一的损失函数，可用于自监督学习或监督学习。

我们得到的损失函数 SupCon 实现简单且训练稳定，实证结果表明了这一点。它在 ImageNet 数据集上使用 ResNet-50 和 ResNet-200 架构实现了出色的 top-1 准确率 [17]。在 ResNet-200 [5] 上，我们实现了 81.4% 的 top-1 准确率，比相同架构上的现有最佳交叉熵损失 [30] 提高了 0.8%（见图 1）。top-1 准确率的提升伴随着在 ImageNet-C 数据集 [19] 上测量的鲁棒性的增强。我们的主要贡献总结如下：

1. 我们提出了一种对比损失函数的新扩展，它允许每个锚点有多个正样本，从而将对比学习适应到完全监督的环境中。从理论分析和实证研究来看，我们表明一种简单的扩展方式的表现远不如我们所提出的版本。（创新点所在：将(无)自监督的对比学习运用到有监督学习中, 同时充分利用label）
2. 我们表明，我们的损失函数在多个数据集上始终能提升 top-1 准确率，并且对自然干扰也更具鲁棒性。（即准确率也高，抗干扰能力也强）
3. 我们通过分析表明，我们损失函数的梯度鼓励从难正例和难反例中学习。(这是什么意思？)
4. 我们通过实证表明，与交叉熵相比，我们的损失函数对一系列超参数的敏感度更低。(对超参数低敏感)

## 2 Related Work

我们的工作借鉴了自监督表示学习、度量学习和监督学习方面的现有文献。这里我们重点关注最相关的论文。交叉熵损失被引入作为训练深度网络的强大损失函数[40, 1, 29]。其核心思想简单直观：每个类别都被分配一个目标（通常是 one-hot）向量。然而，尚不清楚为何这些目标标签应是最优的，一些工作试图确定更好的目标标签向量，例如[57]。许多论文研究了交叉熵损失的其他缺陷，例如对噪声标签的敏感性[64, 46]、对抗样本的存在[10, 36]以及差的边际[2]。虽然提出了替代loss，但在实践中最有效的想法是改变参考标签分布的方法，例如标签平滑[47, 35]、诸如 Mixup [61] 和 CutMix [60] 的数据增强以及知识蒸馏[21]。

基于深度学习模型的强大的自监督表示学习方法最近在自然语言领域得到了发展[8, 58, 33]。在图像领域，像素预测方法也被用于学习嵌入[9, 62, 63, 37]。这些方法试图预测输入信号中缺失的部分。然而，一种更有效的方法是用低维表示空间中的损失来替代密集的逐像素预测损失。使用这种范式的自监督表示学习的最新模型系列被归入对比学习的范畴[55, 18, 22, 48, 43, 3, 51]。在这些工作中，损失的灵感来自于噪声对比估计[13, 34]或 N 对损失[45]。通常，损失应用于深度网络的最后一层。在测试时，利用先前层的嵌入进行下游迁移任务、微调或直接检索任务。[15]引入了仅通过部分损失进行反向传播的近似方法，以及使用以记忆库形式存在的过时表示的近似方法。
 
与对比学习紧密相关的是基于度量距离学习或三元组损失函数家族[4, 53, 42]。这些损失函数通常被应用于监督学习环境中，用于学习强大的表示形式，其中标签信息被用来指导正负样本对的选择。三元组损失与对比损失的核心区别在于每个数据点所使用的正负样本对的数量；具体而言，三元组损失针对每个锚点仅使用一个正样本和一个负样本。在监督度量学习中，正样本对通常从同一类别中选取，而负样本对则从其他类别中选取。为了获得良好的性能，通常需要进行难负样本挖掘[42]。自监督对比损失同样为每个锚点仅选择一个正样本对，其选择方式可通过共现关系[18, 22, 48]或数据增强技术[3]实现。主要的区别在于，自监督方法为每个锚点引入了大量负样本对。这些负样本对通常依据某种弱知识形式以均匀随机的方式选取，例如从其他图像中抽取的补丁或从其他随机视频帧中选取的数据，其基本假设是这种方法产生假阴性的概率极低。

与我们的监督对比方法类似的是在[41]中引入并在[54]中使用的软最近邻损失。与[54]一样，我们通过将嵌入进行归一化处理并用内积替换欧几里得距离对[41]进行了改进。我们进一步改进了[54]，增加了数据增强的使用、一次性对比头以及两阶段训练（先对比后交叉熵），并且关键的是，改变了损失函数的形式以显著提高结果（见第3节）。[12]也使用了与我们非常接近的损失公式，通过最大化损失来纠缠中间层的表示。与我们的方法最相似的是Kamnitsas等人[24]中的紧凑聚类通过标签传播（CCLP）正则化器。虽然CCLP主要关注半监督情况，但在完全监督的情况下，该正则化器几乎完全等同于我们的损失公式。重要的实际差异包括我们将对比嵌入归一化到单位球面上、在对比目标中调整温度参数以及更强的数据增强。此外，Kamnitsas 等人将对比嵌入作为分类头的输入，该分类头与 CCLP 正则化器联合训练，而 SupCon 则采用两阶段训练并舍弃对比头。最后，Kamnitsas 等人的实验规模远小于本研究。将我们论文的发现与 CCLP 相结合是半监督学习研究的一个有前景的方向。


## 3 Method
我们的方法在结构上与用于自监督对比学习的[48, 3]中的方法类似，但针对监督分类进行了修改。给定一批输入数据，我们首先对其进行两次数据增强以获得该批数据的两个副本。这两个副本都通过编码器网络进行前向传播，以获得一个 2048 维的归一化嵌入。在训练期间，此表示会进一步通过一个投影网络进行传播，该网络在推理时会被丢弃。监督对比损失是基于投影网络的输出计算的。为了将训练好的模型用于分类，我们在冻结的表示之上训练一个线性分类器，并使用交叉熵损失。补充材料中的图 1 提供了视觉解释。

### 3.1 Representation Learning Framework

我们的框架的主要组成部分是:

- 数据增强模块 Aug(·)。对于每个输入样本 x，我们生成两个随机增强样本 x˜ = Aug(x)，每个样本代表数据的不同视角，并包含原始样本信息的某个子集。第 4 节给出了增强的具体细节。
- 编码器网络 Enc(·) 将 x 映射为表示向量 r = Enc(x) ∈ RDE 。两个增强样本分别输入到相同的编码器中，从而得到一对表示向量。r 在 RDE 中被归一化到单位超球面上（在本文的所有实验中，DE = 2048）。与 [42, 52] 的发现一致，我们的分析和实验表明这种归一化提高了 top-1 准确率。
- 投影网络 Proj(·) 将 r 映射到一个向量 z = Proj(r) ∈ RDP 中。我们将 Proj(·) 实例化为具有单个 2048 大小隐藏层和大小为 DP = 128 的输出向量的多层感知机 [14] 或者只是大小为 DP = 128 的单个线性层；我们将在未来的工作中研究最优的 Proj(·) 架构。我们再次将此网络的输出归一化到单位超球面上，这使得可以使用内积来测量投影空间中的距离。与自监督对比学习 [48, 3] 一样，在对比训练结束时我们丢弃 Proj(·)。因此，我们的推理时间模型包含的参数数量与使用相同编码器 Enc(·) 的交叉熵模型完全相同。

### 3.2 Contrastive Loss Functions
基于此框架，我们现在来研究对比损失函数这一系列方法，从自监督领域入手，并分析将其应用于监督领域的各种选择，表明其中一种形式更优。对于随机抽取的 N 个样本/标签对集合 {xk, yk}k=1...N ，用于训练的相应批次由 2N 对组成，即 {x˜` , y˜` }` =1...2N ，其中 x˜2k 和 x˜2k−1 是 xk (k = 1...N) 的两种随机增强（也称为“视图”），且 y˜2k−1 = y˜2k = yk 。在本文的其余部分，我们将 N 个样本的集合称为“批次”，而 2N 个增强样本的集合称为“多视图批次”。